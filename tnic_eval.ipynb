{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a4ac24",
   "metadata": {},
   "source": [
    "\n",
    "# TNIC 유사도 네트워크 평가 + 시각화 노트북\n",
    "\n",
    "이 노트북은\n",
    "1) TF-IDF / BERT / LLM 등으로 생성된 edge(jsonl)를 불러오고  \n",
    "2) 재무지표 엑셀과 merge 한 뒤 간단 평가 지표를 계산하고  \n",
    "3) 마지막에 네트워크 시각화를 확인할 수 있도록 구성되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1b843",
   "metadata": {},
   "source": [
    "## 0. 환경 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# (선택) Colab에서 Drive를 쓰는 경우에만 실행하세요.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccad844",
   "metadata": {},
   "source": [
    "## 1. 입력 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caad51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재무지표 엑셀(최소 컬럼: PeerName, year, K, W)\n",
    "METRICS_XLSX = \"evaluation/evaluation_metrics_1128.xlsx\"\n",
    "\n",
    "# 방법별 edge 파일 정의\n",
    "METHOD_FILES = {\n",
    "    \"TFIDF\": \"output/v2/tfidf/TFIDF_2024.jsonl\",\n",
    "    \"BERT\":  \"output/v2/tfidf/BERT_2024_thr0975.jsonl\",\n",
    "    \"LLM\":   \"output/v2/tfidf/OPENAI_2024_thr084.jsonl\",\n",
    "}\n",
    "\n",
    "# (선택) 특정 연도만 분석하고 싶으면 숫자를 넣고, 전체면 None\n",
    "YEAR_FILTER = None  # 예: 2024\n",
    "\n",
    "print(\"METRICS_XLSX:\", METRICS_XLSX)\n",
    "print(\"METHOD_FILES:\", METHOD_FILES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0be5c9",
   "metadata": {},
   "source": [
    "## 2. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_edges_jsonl(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_json(path, lines=True)\n",
    "    return df\n",
    "\n",
    "dfs = {}\n",
    "for name, fp in METHOD_FILES.items():\n",
    "    dfs[name] = read_edges_jsonl(fp)\n",
    "    print(name, \"rows:\", len(dfs[name]), \"cols(head):\", list(dfs[name].columns)[:15])\n",
    "\n",
    "df_T = pd.read_excel(METRICS_XLSX)\n",
    "print(\"metrics rows:\", len(df_T), \"cols:\", list(df_T.columns))\n",
    "df_T.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ab75d",
   "metadata": {},
   "source": [
    "## 3. 재무지표 merge (firm_i / firm_j 각각 붙이기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_with_metrics(df_edges: pd.DataFrame, df_metrics: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = df_metrics[[\"PeerName\", \"year\", \"K\", \"W\"]].copy()\n",
    "\n",
    "    # firm_i merge\n",
    "    m_i = base.rename(columns={\"PeerName\": \"firm_i_name\", \"K\": \"K_i\", \"W\": \"W_i\"})\n",
    "    out = df_edges.merge(m_i, how=\"left\", on=[\"firm_i_name\", \"year\"])\n",
    "\n",
    "    # firm_j merge\n",
    "    m_j = base.rename(columns={\"PeerName\": \"firm_j_name\", \"K\": \"K_j\", \"W\": \"W_j\"})\n",
    "    out = out.merge(m_j, how=\"left\", on=[\"firm_j_name\", \"year\"])\n",
    "    return out\n",
    "\n",
    "dfs_m = {}\n",
    "for name, df in dfs.items():\n",
    "    d = df.copy()\n",
    "    if YEAR_FILTER is not None and \"year\" in d.columns:\n",
    "        d = d[d[\"year\"] == YEAR_FILTER].copy()\n",
    "    dfs_m[name] = merge_with_metrics(d, df_T)\n",
    "    print(name, \"after merge rows:\", len(dfs_m[name]))\n",
    "\n",
    "dfs_m[\"LLM\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e202d86",
   "metadata": {},
   "source": [
    "\n",
    "## 4. 평가 지표 계산 (기본 버전)\n",
    "\n",
    "노트북 단독 사용을 위해 범용 지표를 제공합니다.\n",
    "\n",
    "- abs_delta_K = |K_i - K_j|\n",
    "- abs_delta_W = |W_i - W_j|\n",
    "- missing_rate = K/W merge 결측 비율\n",
    "- similarity 분포 요약\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80443404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_eval_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in [\"K_i\", \"K_j\", \"W_i\", \"W_j\"]:\n",
    "        if c not in out.columns:\n",
    "            out[c] = np.nan\n",
    "\n",
    "    out[\"abs_delta_K\"] = (out[\"K_i\"] - out[\"K_j\"]).abs()\n",
    "    out[\"abs_delta_W\"] = (out[\"W_i\"] - out[\"W_j\"]).abs()\n",
    "\n",
    "    # self-edge 제거(있으면)\n",
    "    if \"firm_i\" in out.columns and \"firm_j\" in out.columns:\n",
    "        out = out[out[\"firm_i\"] != out[\"firm_j\"]].copy()\n",
    "    return out\n",
    "\n",
    "dfs_e = {name: add_eval_cols(df) for name, df in dfs_m.items()}\n",
    "\n",
    "def summarize_method(df: pd.DataFrame, method_name: str) -> dict:\n",
    "    total = len(df)\n",
    "    sim = df[\"similarity\"] if \"similarity\" in df.columns else pd.Series(dtype=float)\n",
    "    return {\n",
    "        \"method\": method_name,\n",
    "        \"rows\": total,\n",
    "        \"missing_rate_K\": float(df[\"abs_delta_K\"].isna().mean()) if total else np.nan,\n",
    "        \"missing_rate_W\": float(df[\"abs_delta_W\"].isna().mean()) if total else np.nan,\n",
    "        \"sim_mean\": float(sim.mean()) if len(sim) else np.nan,\n",
    "        \"sim_median\": float(sim.median()) if len(sim) else np.nan,\n",
    "        \"sim_p90\": float(sim.quantile(0.90)) if len(sim) else np.nan,\n",
    "        \"sim_p95\": float(sim.quantile(0.95)) if len(sim) else np.nan,\n",
    "    }\n",
    "\n",
    "summary = pd.DataFrame([summarize_method(df, name) for name, df in dfs_e.items()])\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9443532",
   "metadata": {},
   "source": [
    "### 4.1 Top-N edge만 평가 (similarity 상위 N개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21424097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TOP_N = 20000  # 데이터 크기에 맞게 조절\n",
    "\n",
    "def topn_eval(df: pd.DataFrame, n: int) -> dict:\n",
    "    if \"similarity\" not in df.columns or len(df) == 0:\n",
    "        return {\"top_n\": n, \"mean_abs_delta_K\": np.nan, \"mean_abs_delta_W\": np.nan}\n",
    "    d = df.sort_values(\"similarity\", ascending=False).head(n)\n",
    "    return {\n",
    "        \"top_n\": n,\n",
    "        \"mean_abs_delta_K\": float(d[\"abs_delta_K\"].mean()),\n",
    "        \"mean_abs_delta_W\": float(d[\"abs_delta_W\"].mean()),\n",
    "        \"median_abs_delta_K\": float(d[\"abs_delta_K\"].median()),\n",
    "        \"median_abs_delta_W\": float(d[\"abs_delta_W\"].median()),\n",
    "    }\n",
    "\n",
    "topn_table = []\n",
    "for name, df in dfs_e.items():\n",
    "    row = {\"method\": name}\n",
    "    row.update(topn_eval(df, TOP_N))\n",
    "    topn_table.append(row)\n",
    "\n",
    "pd.DataFrame(topn_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba1e21f",
   "metadata": {},
   "source": [
    "### 4.2 similarity vs |K_i-K_j| / |W_i-W_j| 상관(참고용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23efcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def corr_safe(df: pd.DataFrame, x: str, y: str) -> float:\n",
    "    d = df[[x, y]].dropna()\n",
    "    if len(d) < 3:\n",
    "        return np.nan\n",
    "    return float(d[x].corr(d[y]))\n",
    "\n",
    "corr_rows = []\n",
    "for name, df in dfs_e.items():\n",
    "    corr_rows.append({\n",
    "        \"method\": name,\n",
    "        \"corr(sim, abs_delta_K)\": corr_safe(df, \"similarity\", \"abs_delta_K\"),\n",
    "        \"corr(sim, abs_delta_W)\": corr_safe(df, \"similarity\", \"abs_delta_W\"),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(corr_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbbf305",
   "metadata": {},
   "source": [
    "### 4.3 간단 플롯(분포/산점도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a64a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "METHOD_TO_PLOT = \"LLM\"  # \"TFIDF\" / \"BERT\" / \"LLM\"\n",
    "dfp = dfs_e[METHOD_TO_PLOT].copy()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "dfp[\"similarity\"].dropna().hist(bins=50)\n",
    "plt.title(f\"Similarity distribution: {METHOD_TO_PLOT}\")\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "SAMPLE_N = 30000\n",
    "d2 = dfp[[\"similarity\", \"abs_delta_K\", \"abs_delta_W\"]].dropna()\n",
    "if len(d2) > SAMPLE_N:\n",
    "    d2 = d2.sample(SAMPLE_N, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(d2[\"similarity\"], d2[\"abs_delta_K\"], s=3, alpha=0.3)\n",
    "plt.title(f\"Similarity vs |K_i-K_j| (sample): {METHOD_TO_PLOT}\")\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"|K_i - K_j|\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(d2[\"similarity\"], d2[\"abs_delta_W\"], s=3, alpha=0.3)\n",
    "plt.title(f\"Similarity vs |W_i-W_j| (sample): {METHOD_TO_PLOT}\")\n",
    "plt.xlabel(\"similarity\")\n",
    "plt.ylabel(\"|W_i - W_j|\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab65557",
   "metadata": {},
   "source": [
    "## 5. (시각화) 한글 폰트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc945dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# (선택) Colab/Ubuntu 기준 폰트 설치가 필요하면 아래를 실행\n",
    "# !apt-get update -y\n",
    "# !apt-get install -y fonts-nanum\n",
    "\n",
    "font_candidates = [\n",
    "    \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\",\n",
    "    \"/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf\",\n",
    "]\n",
    "\n",
    "font_path = None\n",
    "for p in font_candidates:\n",
    "    if os.path.exists(p):\n",
    "        font_path = p\n",
    "        break\n",
    "\n",
    "if font_path:\n",
    "    fm.fontManager.addfont(font_path)\n",
    "    font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "    plt.rcParams[\"font.family\"] = font_name\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "    print(\"Using font:\", font_name, \"(\", font_path, \")\")\n",
    "else:\n",
    "    font_name = None\n",
    "    print(\"Nanum font not found. Proceeding with default matplotlib font.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d71f2",
   "metadata": {},
   "source": [
    "\n",
    "## 6. (시각화) 중심 기업 네트워크\n",
    "\n",
    "- CENTER_NAME이 None이면, edge에 가장 많이 등장하는 기업을 자동으로 중심으로 잡습니다.\n",
    "- SIM_THRESHOLD / TOP_K_PER_NODE로 sparsify 강도를 조절합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "\n",
    "METHOD_VIZ = \"LLM\"   # \"TFIDF\" / \"BERT\" / \"LLM\"\n",
    "YEAR_VIZ = YEAR_FILTER  # None이면 필터 없이 진행\n",
    "CENTER_NAME = None   # 예: \"동성화인텍\"\n",
    "SIM_THRESHOLD = 0.88\n",
    "TOP_K_PER_NODE = 5\n",
    "\n",
    "df = dfs_e[METHOD_VIZ].copy()\n",
    "if YEAR_VIZ is not None and \"year\" in df.columns:\n",
    "    df = df[df[\"year\"] == YEAR_VIZ].copy()\n",
    "\n",
    "df = df[df[\"similarity\"] >= SIM_THRESHOLD].copy()\n",
    "print(\"edges after threshold:\", len(df))\n",
    "\n",
    "if len(df) == 0:\n",
    "    raise ValueError(\"No edges left after threshold. Lower SIM_THRESHOLD.\")\n",
    "\n",
    "if CENTER_NAME is None:\n",
    "    counts = pd.concat([df[\"firm_i_name\"], df[\"firm_j_name\"]]).value_counts()\n",
    "    CENTER_NAME = counts.index[0]\n",
    "print(\"CENTER_NAME =\", CENTER_NAME)\n",
    "\n",
    "mask_center = (df[\"firm_i_name\"] == CENTER_NAME) | (df[\"firm_j_name\"] == CENTER_NAME)\n",
    "df_center = df[mask_center].copy()\n",
    "\n",
    "neighbors = pd.unique(df_center[[\"firm_i_name\", \"firm_j_name\"]].values.ravel())\n",
    "neighbors = [n for n in neighbors if n != CENTER_NAME]\n",
    "\n",
    "mask_sub = df[\"firm_i_name\"].isin([CENTER_NAME] + neighbors) | df[\"firm_j_name\"].isin([CENTER_NAME] + neighbors)\n",
    "df_sub = df[mask_sub].copy()\n",
    "\n",
    "df_sorted = df_sub.sort_values(\"similarity\", ascending=False)\n",
    "\n",
    "grp_i = \"firm_i\" if \"firm_i\" in df_sorted.columns else \"firm_i_name\"\n",
    "grp_j = \"firm_j\" if \"firm_j\" in df_sorted.columns else \"firm_j_name\"\n",
    "\n",
    "keep_i = df_sorted.groupby(grp_i).head(TOP_K_PER_NODE)\n",
    "keep_j = df_sorted.groupby(grp_j).head(TOP_K_PER_NODE)\n",
    "df_sub = pd.concat([keep_i, keep_j]).drop_duplicates()\n",
    "\n",
    "print(\"subgraph edges:\", len(df_sub))\n",
    "df_sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6010d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src = \"firm_i\" if \"firm_i\" in df_sub.columns else \"firm_i_name\"\n",
    "tgt = \"firm_j\" if \"firm_j\" in df_sub.columns else \"firm_j_name\"\n",
    "\n",
    "G = nx.from_pandas_edgelist(\n",
    "    df_sub,\n",
    "    source=src,\n",
    "    target=tgt,\n",
    "    edge_attr=\"similarity\",\n",
    "    create_using=nx.Graph()\n",
    ")\n",
    "\n",
    "# 노드 속성: 이름/섹터(W)\n",
    "for _, r in df_sub.iterrows():\n",
    "    ni = r.get(src)\n",
    "    nj = r.get(tgt)\n",
    "\n",
    "    if ni in G:\n",
    "        G.nodes[ni][\"name\"] = r.get(\"firm_i_name\", str(ni))\n",
    "        G.nodes[ni][\"sector\"] = r.get(\"W_i\", \"Unknown\")\n",
    "    if nj in G:\n",
    "        G.nodes[nj][\"name\"] = r.get(\"firm_j_name\", str(nj))\n",
    "        G.nodes[nj][\"sector\"] = r.get(\"W_j\", \"Unknown\")\n",
    "\n",
    "for n in G.nodes():\n",
    "    if \"sector\" not in G.nodes[n] or pd.isna(G.nodes[n][\"sector\"]):\n",
    "        G.nodes[n][\"sector\"] = \"Unknown\"\n",
    "    if \"name\" not in G.nodes[n] or pd.isna(G.nodes[n][\"name\"]):\n",
    "        G.nodes[n][\"name\"] = str(n)\n",
    "\n",
    "sectors = sorted({G.nodes[n][\"sector\"] for n in G.nodes()})\n",
    "cmap = plt.get_cmap(\"tab20\", max(1, len(sectors)))\n",
    "sector_to_color = {s: cmap(i) for i, s in enumerate(sectors)}\n",
    "node_colors = [sector_to_color[G.nodes[n][\"sector\"]] for n in G.nodes()]\n",
    "edge_widths = [float(G[u][v][\"similarity\"]) * 5 for u, v in G.edges()]\n",
    "\n",
    "pos = nx.spring_layout(G, k=0.8, seed=42)\n",
    "\n",
    "node_sizes = []\n",
    "for n in G.nodes():\n",
    "    node_sizes.append(900 if G.nodes[n][\"name\"] == CENTER_NAME else 320)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.9)\n",
    "nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.55)\n",
    "\n",
    "labels = {n: G.nodes[n][\"name\"] for n in G.nodes()}\n",
    "nx.draw_networkx_labels(G, pos, labels=labels, font_size=10)\n",
    "\n",
    "plt.title(f\"[{METHOD_VIZ}] Center similarity network: {CENTER_NAME} (th={SIM_THRESHOLD}, topk={TOP_K_PER_NODE})\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf6b02",
   "metadata": {},
   "source": [
    "\n",
    "## 7. (선택) cap/WICS 네트워크\n",
    "\n",
    "데이터에 `cap`, `WICS` 컬럼이 있을 때만 사용하세요.  \n",
    "없으면 이 섹션은 건너뛰시면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx as nx\n",
    "\n",
    "METHOD_CAP = \"BERT\"\n",
    "YEAR_SEL = YEAR_FILTER if YEAR_FILTER is not None else 2019\n",
    "SIM_TH = 0.3\n",
    "\n",
    "dfc = dfs.get(METHOD_CAP, None)\n",
    "if dfc is None:\n",
    "    raise ValueError(f\"Unknown method: {METHOD_CAP}\")\n",
    "\n",
    "dfc = dfc.copy()\n",
    "if \"year\" in dfc.columns:\n",
    "    dfc = dfc[dfc[\"year\"] == YEAR_SEL].copy()\n",
    "\n",
    "needed = {\"cap\", \"WICS\", \"firm_i\", \"firm_j\", \"similarity\"}\n",
    "missing = needed - set(dfc.columns)\n",
    "if missing:\n",
    "    print(\"cap/WICS plot skipped. Missing columns:\", missing)\n",
    "else:\n",
    "    dfc = dfc[dfc[\"similarity\"] >= SIM_TH].copy()\n",
    "    print(\"edges:\", len(dfc))\n",
    "\n",
    "    nodes_i = dfc[[\"firm_i\", \"WICS\", \"cap\"]].rename(columns={\"firm_i\": \"node\"})\n",
    "    nodes_j = dfc[[\"firm_j\", \"WICS\", \"cap\"]].rename(columns={\"firm_j\": \"node\"})\n",
    "    nodes_df = pd.concat([nodes_i, nodes_j], ignore_index=True).drop_duplicates(subset=\"node\").set_index(\"node\")\n",
    "\n",
    "    wics_attr = nodes_df[\"WICS\"].to_dict()\n",
    "    cap_attr = nodes_df[\"cap\"].to_dict()\n",
    "\n",
    "    G2 = nx.from_pandas_edgelist(dfc, source=\"firm_i\", target=\"firm_j\", edge_attr=\"similarity\", create_using=nx.Graph())\n",
    "    nx.set_node_attributes(G2, wics_attr, \"WICS\")\n",
    "    nx.set_node_attributes(G2, cap_attr, \"cap\")\n",
    "\n",
    "    pos2 = nx.spring_layout(G2, k=0.25, weight=\"similarity\", iterations=100, seed=42)\n",
    "\n",
    "    nodes = list(G2.nodes())\n",
    "    wics = np.array([G2.nodes[n].get(\"WICS\", np.nan) for n in nodes], dtype=float)\n",
    "    caps = np.array([G2.nodes[n].get(\"cap\", np.nan) for n in nodes], dtype=float)\n",
    "\n",
    "    if np.isnan(caps).any():\n",
    "        non = caps[~np.isnan(caps)]\n",
    "        caps[np.isnan(caps)] = np.nanmin(non) if len(non) else 1.0\n",
    "    if np.isnan(wics).any():\n",
    "        wics[np.isnan(wics)] = 0.0\n",
    "\n",
    "    cap_log = np.log1p(caps)\n",
    "    denom = (cap_log.max() - cap_log.min()) + 1e-9\n",
    "    cap_norm = (cap_log - cap_log.min()) / denom\n",
    "    node_sizes = 60 + cap_norm * 1900\n",
    "\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", 20)\n",
    "\n",
    "    edge_colors = []\n",
    "    for u, v in G2.edges():\n",
    "        wu = G2.nodes[u].get(\"WICS\", 0)\n",
    "        try:\n",
    "            w_norm = (float(wu) - 1) / 19\n",
    "        except Exception:\n",
    "            w_norm = 0.0\n",
    "        edge_colors.append(cmap(w_norm))\n",
    "\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    nx.draw_networkx_edges(\n",
    "        G2, pos2,\n",
    "        edge_color=edge_colors,\n",
    "        width=[float(G2[u][v][\"similarity\"]) * 1.5 for u, v in G2.edges()],\n",
    "        alpha=0.35,\n",
    "    )\n",
    "    nx.draw_networkx_nodes(\n",
    "        G2, pos2,\n",
    "        nodelist=nodes,\n",
    "        node_size=node_sizes,\n",
    "        node_color=wics,\n",
    "        cmap=cmap,\n",
    "        vmin=1, vmax=20,\n",
    "        linewidths=0.2,\n",
    "        edgecolors=\"black\",\n",
    "        alpha=0.95,\n",
    "    )\n",
    "\n",
    "    plt.title(f\"[{METHOD_CAP}] cap/WICS network (year={YEAR_SEL}, th={SIM_TH})\\nnode color=WICS, node size=cap, edge=similarity\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
