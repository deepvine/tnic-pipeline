import xml.etree.ElementTree as ET

def load_corp_list_from_dart(api_key):
    """
    DART corpCode APIì—ì„œ ì „ì²´ ê¸°ì—… ëª©ë¡ì„ ë°›ì•„ì„œ DataFrameìœ¼ë¡œ ë°˜í™˜.
    corp_code, corp_name, stock_code í¬í•¨.
    """
    url = "https://opendart.fss.or.kr/api/corpCode.xml"
    params = {"crtfc_key": api_key}

    # corpCode.xml ZIP ë‹¤ìš´ë¡œë“œ
    r = requests.get(url, params=params, timeout=30)
    if r.status_code != 200:
        raise RuntimeError(f"corpCode.xml ìš”ì²­ ì‹¤íŒ¨: HTTP {r.status_code}")

    # ZIP ì••ì¶• í’€ê¸°
    zf = zipfile.ZipFile(io.BytesIO(r.content))
    xml_name = [n for n in zf.namelist() if n.lower().endswith(".xml")][0]
    xml_bytes = zf.read(xml_name)

    # XML íŒŒì‹±
    root = ET.fromstring(xml_bytes)

    rows = []
    for el in root.findall("list"):
        corp_code = el.findtext("corp_code")
        corp_name = el.findtext("corp_name")
        stock_code = el.findtext("stock_code")

        rows.append({
            "corp_code": corp_code,
            "corp_name": corp_name,
            "stock_code": stock_code,
        })

    df = pd.DataFrame(rows)
    return df


import os
import io
import json
import time
import zipfile
import requests
import pandas as pd
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

# =========================================
# 0. í™˜ê²½ ì„¤ì •
# =========================================
API_KEY = "key"   # ë³¸ì¸ API KEY
OUTPUT_DIR = "/content//matched_files"
os.makedirs(OUTPUT_DIR, exist_ok=True)

FAILED_LIST_FILE = "/content/failed_reports1213.jsonl"

DOC_URL = "https://opendart.fss.or.kr/api/document.xml"
LIST_URL = "https://opendart.fss.or.kr/api/list.json"


# =========================================
# ì‹¤íŒ¨ ë¦¬ìŠ¤íŠ¸ ê¸°ë¡ í•¨ìˆ˜
# =========================================
def log_failed_report(corp_code, corp_name, rcept_no, error_message):
    failed_report = {
        "corp_code": corp_code,
        "corp_name": corp_name,
        "rcept_no": rcept_no,
        "error_message": error_message
    }

    with open(FAILED_LIST_FILE, "a", encoding="utf-8") as f:
        json.dump(failed_report, f, ensure_ascii=False)
        f.write("\n")


# =========================================
# 1. ì‚¬ì—…ë³´ê³ ì„œ ëª©ë¡ ì¡°íšŒ
# =========================================
def get_business_reports(corp_code):
    all_reports = []
    page_no = 1

    while True:
        params = {
            "crtfc_key": API_KEY,
            "corp_code": corp_code,
            "bgn_de": "20050101",
            "end_de": "20251231",
            "last_reprt_at": "N",
            "pblntf_ty": "A",
            "pblntf_detail_ty": "A001",
            "page_no": page_no,
            "page_count": 100
        }

        res = requests.get(LIST_URL, params=params).json()

        if res.get("status") != "000":
            print(f"corp_code={corp_code} ì‚¬ì—…ë³´ê³ ì„œ ì¡°íšŒ ì‹¤íŒ¨: {res.get('message')}")
            break

        reports = res.get("list", []) or []
        if not reports:
            break

        all_reports.extend(reports)

        if len(reports) < 100:
            break

        page_no += 1
        time.sleep(0.05)  # ìµœì†Œ ëŒ€ê¸°

    biz_reports = [r for r in all_reports if "ì‚¬ì—…ë³´ê³ ì„œ" in r.get("report_nm", "")]
    biz_reports.sort(key=lambda x: x.get("rcept_dt", ""), reverse=True)

    print(f" ìµœì¢… ì‚¬ì—…ë³´ê³ ì„œ {len(biz_reports)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
    return biz_reports


# =========================================
# 2. HTML íƒœê·¸ ì œê±° (ì´ˆê³ ì†)
# =========================================
TAG_RE = re.compile(r"<[^>]+>")

def strip_html_fast(html):
    return TAG_RE.sub("", html)


# =========================================
# 3. ZIP â†’ XML â†’ ì‚¬ì—…ì˜ ë‚´ìš© ì¶”ì¶œ (ê³ ì†)
# =========================================
def fetch_business_text_only(rcept_no):

    params = {"crtfc_key": API_KEY, "rcept_no": str(rcept_no)}

    try:
        r = requests.get(DOC_URL, params=params, timeout=20)
    except Exception as e:
        return None, f"HTTP ìš”ì²­ ì‹¤íŒ¨: {e}"

    if r.status_code != 200:
        return None, f"HTTP ìƒíƒœì½”ë“œ {r.status_code}"

    # ZIP ì½ê¸°
    try:
        zf = zipfile.ZipFile(io.BytesIO(r.content))
    except Exception as e:
        return None, f"ZIP ì˜¤ë¥˜: {e}"

    # zip ë‚´ XML íŒŒì¼ ë°”ë¡œ ì„ íƒ
    xml_files = [f for f in zf.namelist() if f.endswith(".xml")]
    if not xml_files:
        return None, "XML íŒŒì¼ ì—†ìŒ"

    raw = zf.read(xml_files[0])

    # ì¸ì½”ë”© ì‹œë„
    for enc in ("utf-8", "euc-kr", "cp949"):
        try:
            xml_text = raw.decode(enc)
            break
        except:
            xml_text = None

    if xml_text is None:
        return None, "XML ë””ì½”ë”© ì‹¤íŒ¨"

   # II. ì‚¬ì—…ì˜ ë‚´ìš©(ë³´í—˜ì—…) ê°™ì€ ë³€í˜•ê¹Œì§€ ëª¨ë‘ ì¡ê¸°
    m_start = re.search(r'<TITLE[^>]*>\s*II\.\s*ì‚¬ì—…ì˜\s*ë‚´ìš©.*?</TITLE>', xml_text)
    m_end   = re.search(r'<TITLE[^>]*>\s*III\.\s*ì¬ë¬´ì—\s*ê´€í•œ\s*ì‚¬í•­.*?</TITLE>', xml_text)

    if not m_start or not m_end:
        return None, "ì‚¬ì—…ì˜ ë‚´ìš©/ì¬ë¬´ ì„¹ì…˜ TITLE ë¯¸ê²€ì¶œ"

    start = m_start.start()
    end = m_end.start()

    if end <= start:
        return None, "ì„¹ì…˜ ìœ„ì¹˜ ì—­ì „(íŒŒì‹± ì´ìƒ)"

    block = xml_text[start:end]


    # íƒœê·¸ ì œê±° (ì´ˆê³ ì†)
    text_only = strip_html_fast(block).strip()

    if not text_only:
        return None, "ì‚¬ì—…ì˜ ë‚´ìš© í…ìŠ¤íŠ¸ ì—†ìŒ"

    return text_only, None


# =========================================
# 4. ì €ì¥ í•¨ìˆ˜
# =========================================
def save_business_section(corp_code, corp_name, year, rcept_no, report_nm):

    text, err = fetch_business_text_only(rcept_no)
    if text is None:
        print(f"ì‹¤íŒ¨: rcept_no={rcept_no}, ì‚¬ìœ : {err}")
        log_failed_report(corp_code, corp_name, rcept_no, err)  # ì‹¤íŒ¨ ë¦¬ìŠ¤íŠ¸ì— ê¸°ë¡
        return False

    fname = f"{corp_code}_{report_nm}_{corp_name}_{rcept_no}"
    fname = re.sub(r'[\\/:*?"<>|]', "_", fname)

    out_path = os.path.join(OUTPUT_DIR, fname + ".jsonl")

    obj = {
        "corp_code": corp_code,
        "corp_name": corp_name,
        "rcept_no": rcept_no,
        "year": year,
        "report_nm": report_nm,
        "parsed_business_content": text
    }

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False)

    print(f"âœ” ì €ì¥ ì™„ë£Œ: {out_path}")
    return True


# =========================================
# 5. íšŒì‚¬ë³„ ì „ì²´ ì²˜ë¦¬ â€” ë³‘ë ¬ ì²˜ë¦¬ë¡œ í¬ê²Œ ê°€ì†
# =========================================
def process_corp_code(corp_code, corp_name, idx, total_rows):
    print(f"\n==============================")
    print(f" [{idx}/{total_rows}] corp_code={corp_code}, corp_name={corp_name} ì²˜ë¦¬ ì‹œì‘")
    print(f"==============================")

    reports = get_business_reports(corp_code)
    if len(reports) == 0:
        print(f"ì‚¬ì—…ë³´ê³ ì„œ ì—†ìŒ: {corp_code}")
        return

    print(f" ì‚¬ì—…ë³´ê³ ì„œ {len(reports)}ê°œ ë°œê²¬")

    tasks = []
    with ThreadPoolExecutor(max_workers=8) as executor:   # ë³‘ë ¬ ì²˜ë¦¬
        for r in reports:
            rcept_no = r["rcept_no"]
            report_nm = r["report_nm"]

            m = re.search(r"\((\d{4})\.", report_nm)
            year = m.group(1) if m else "UNKNOWN"

            tasks.append(
                executor.submit(
                    save_business_section,
                    corp_code, corp_name, year, rcept_no, report_nm
                )
            )

        for f in as_completed(tasks):
            pass  # ì™„ë£Œëœ ì‘ì—… ì²´í¬



# =========================================
# 6. ì‹¤í–‰ë¶€ - DARTì—ì„œ corp_code ì°¾ì€ ë’¤ ëŒ€ìƒ ê¸°ì—…ë§Œ ì²˜ë¦¬ (ì •í™• ì¼ì¹˜)
# =========================================

def normalize_corp_code(raw):
    if pd.isna(raw):
        return None
    s = str(raw).strip()
    if s.endswith(".0"):
        s = s[:-2]
    return s.zfill(8) if s.isdigit() else None

#  1) íƒ€ê²Ÿ íšŒì‚¬ëª… (corp_nameê³¼ ì •í™•íˆ ê°™ì€ ë¬¸ìì—´ì´ì–´ì•¼ í•¨)
target_names = ["í˜„ëŒ€ìë™ì°¨"]

print("ğŸ“¥ DART ì—ì„œ ì „ì²´ ê¸°ì—…ëª©ë¡ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
corp_list_df = load_corp_list_from_dart(API_KEY)

# ê³µë°± ì •ë¦¬
corp_list_df["corp_name"] = corp_list_df["corp_name"].astype(str).str.strip()

target_rows = []

#  2) ê¸°ì—…ëª… 'ì •í™• ì¼ì¹˜'ë¡œ ê²€ìƒ‰
for name in target_names:
    name_clean = name.strip()
    matched = corp_list_df[corp_list_df["corp_name"] == name_clean]

    if matched.empty:
        print(f"'{name_clean}' ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê¸°ì—…ì„ corpCodeì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        continue

    print(f"\n '{name_clean}' ì •í™• ì¼ì¹˜ ê²€ìƒ‰ ê²°ê³¼:")
    print(matched[["corp_code", "corp_name", "stock_code"]])

    target_rows.append(matched[["corp_code", "corp_name"]])

# ëª©í‘œ ê¸°ì—… ì—†ìœ¼ë©´ ì¢…ë£Œ
if not target_rows:
    print("\n ëŒ€ìƒ ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
else:
    target_df = pd.concat(target_rows).drop_duplicates().reset_index(drop=True)

    print("\n ìµœì¢… ëŒ€ìƒ ê¸°ì—… ëª©ë¡:")
    print(target_df)

    #  3) ì‚¬ì—…ë³´ê³ ì„œ ë‚´ë ¤ë°›ê¸°
    total_rows = len(target_df)
    for idx, row in target_df.iterrows():
        corp_code = normalize_corp_code(row["corp_code"])
        corp_name = row["corp_name"]

        if corp_code is None:
            print(f" corp_code ì´ìƒ: {row}")
            continue

        print(f"\n ì‹¤í–‰: corp_code={corp_code}, corp_name={corp_name}")
        process_corp_code(corp_code, corp_name, idx + 1, total_rows)

    print("\n ì„ íƒí•œ ê¸°ì—…ë“¤ ì²˜ë¦¬ ì™„ë£Œ!")
